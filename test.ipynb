{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "bad magic number in 'Ipynb_importer': b'\\x03\\xf3\\r\\n'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-84842533058d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mIpynb_importer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m#import Classic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRR_RAPPOR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSubsetselection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: bad magic number in 'Ipynb_importer': b'\\x03\\xf3\\r\\n'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#import Classic\n",
    "import RR_RAPPOR\n",
    "import Subsetselection\n",
    "import k2k_hadamard\n",
    "import timeit\n",
    "import scipy.io as io\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as io\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(k, eps, rep, point_num, step_sz, init, dist, encode_acc = 1, encode_mode = 0):\n",
    "    # fix alphabet size and privacy level, get the error plot with respect to sample size\n",
    "    \n",
    "    #Args:\n",
    "    # k : alphabet size,  eps: privacy level, rep: repetition times to compute a point\n",
    "    # point_num: number of points to compute\n",
    "    # step_sz: distance between two sample sizes\n",
    "    # init: initial sample size = init* step_sz\n",
    "    # dist: underlying data distribution: choose from 'Uniform', 'Two_steps', 'Zipf', 'Dirchlet', 'Geometric'\n",
    "    \n",
    "    # encode_acc : control whether to use fast encoding for hadamard responce\n",
    "    #           recommended and default: 1 use fast encoding when k < 10000\n",
    "    #                                    if memory use is high, disable this\n",
    "    \n",
    "    # mode: control encoding method for rappor and subset selection\n",
    "    #       0 for standard, which is fast but memory intensive\n",
    "    #       1 for light, which is relatively slow but not memory intensive\n",
    "    #       2 for compress, where we compress the output of rappor and subsetselection into locations of ones.\n",
    "    #       recommended and default: 0 when k <= 5000 n <= 1000000\n",
    "    #                               if memory use is high, use light mode\n",
    "    #       you can also create other modes by modifying the code\n",
    "    print('Alphabet size:', k)\n",
    "    print('Privacy level:', eps)\n",
    "    \n",
    "    indicies = [(init-1+i)*step_sz for i in range(1,point_num+1) ] # all the indicies\n",
    "    \n",
    "    subset = Subsetselection.Subsetselection(k,eps) #class for subset selection algorithm\n",
    "    rappor = RR_RAPPOR.RAPPOR(k,eps) #class for RAPPOR\n",
    "    rr = RR_RAPPOR.Randomized_Response(k, eps) #class for Randomized Response\n",
    "    if encode_acc == 1:\n",
    "        hr = k2k_hadamard.Hadamard_Rand_general(k,eps,1) #initialize hadamard response\n",
    "    else:\n",
    "        hr = k2k_hadamard.Hadamard_Rand_general(k,eps,0) #initialize hadamard response\n",
    "    \n",
    "    prob1 = generate_uniform_distribution(k)\n",
    "    prob2 = generate_two_steps_distribution(k)\n",
    "    prob3 = generate_Zipf_distribution(k,1.0)\n",
    "    prob4 = generate_Dirichlet_distribution(k,1.0)\n",
    "    prob5 = generate_geometric_distribution(k,0.8)\n",
    "\n",
    "    prob_list = {\n",
    "        'Uniform' : prob1,\n",
    "        'Two_steps' : prob2,\n",
    "        'Zipf' : prob3,\n",
    "        'Dirchlet' : prob4,\n",
    "        'Geometric' : prob5, \n",
    "        }\n",
    "    #underlying distribution\n",
    "    prob = prob_list[dist]\n",
    "    \n",
    "    # to store l1 errors for each method\n",
    "    l1_1 = [0]*point_num\n",
    "    l1_2 = [0]*point_num\n",
    "    l1_3 = [0]*point_num\n",
    "    l1_4 = [0]*point_num\n",
    "    \n",
    "    # to store l2 errors for each method\n",
    "    l2_1 = [0]*point_num\n",
    "    l2_2 = [0]*point_num\n",
    "    l2_3 = [0]*point_num\n",
    "    l2_4 = [0]*point_num\n",
    "\n",
    "    # to store decodign time for each method\n",
    "    t1_1 = [0]*point_num\n",
    "    t1_2 = [0]*point_num\n",
    "    t1_3 = [0]*point_num\n",
    "    t1_4 = [0]*point_num\n",
    "\n",
    "    for r in range(init, point_num + init):\n",
    "        print('Iteration:', r)\n",
    "        n = r*step_sz\n",
    "        count1 = 0\n",
    "        count2 = 0\n",
    "        count3 = 0\n",
    "        count4 = 0\n",
    "        count2_1 = 0\n",
    "        count2_2 = 0\n",
    "        count2_3 = 0\n",
    "        count2_4 = 0\n",
    "        t1 = 0\n",
    "        t2 = 0\n",
    "        t3 = 0\n",
    "        t4 = 0\n",
    "        for t in range(0,rep):\n",
    "            #print(t)\n",
    "            elements = range(0,k)\n",
    "            in_list = np.random.choice(elements, n, p=prob) #input symbols\n",
    "            \n",
    "            #subset selection\n",
    "            if encode_mode == 0: # standard mode\n",
    "                outp_1 = subset.encode_string_fast(in_list) \n",
    "                start_time = timeit.default_timer()\n",
    "                prob_est_1 = subset.decode_string(outp_1,n) # estimate the original underlying distribution\n",
    "                t1 = t1 + timeit.default_timer() - start_time\n",
    "            if encode_mode == 1: # light mode\n",
    "                counts,time = subset.encode_string_light(in_list) #subset selection\n",
    "                start_time = timeit.default_timer()\n",
    "                prob_est_1 = subset.decode_counts(counts, n) # estimate the original underlying distribution\n",
    "                t1 = t1 + time + timeit.default_timer() - start_time\n",
    "            if encode_mode == 2: # compress mode\n",
    "                out_list = subset.encode_string_compress(in_list) #subset selection\n",
    "                start_time = timeit.default_timer()\n",
    "                counts, temp = np.histogram(out_list,range(k+1))\n",
    "                prob_est_1 = subset.decode_counts(counts, n) # estimate the original underlying distribution\n",
    "                t1 = t1 + timeit.default_timer() - start_time\n",
    "            count1 = count1 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_1)], ord=1) \n",
    "            count2_1 = count2_1 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_1)], ord=2)**2\n",
    "\n",
    "            # k- RR\n",
    "            sample = rr.encode_string(in_list) \n",
    "            start_time = timeit.default_timer()\n",
    "            prob_est_2 = rr.decode_string(sample) # estimate the original underlying distribution\n",
    "            t2 = t2 + timeit.default_timer() - start_time\n",
    "            count2 = count2 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_2)], ord=1) \n",
    "            count2_2 = count2_2 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_2)], ord=2)**2\n",
    "            \n",
    "            #k-RAPPOR\n",
    "            if encode_mode == 0: \n",
    "                sample = rappor.encode_string(in_list) \n",
    "                start_time = timeit.default_timer()\n",
    "                outp_3 = np.sum(sample, axis=0)\n",
    "                prob_est_3 = rappor.decode_counts(outp_3,n) # estimate the original underlying distribution\n",
    "                t3 = t3 + timeit.default_timer() - start_time\n",
    "            if encode_mode == 1:\n",
    "                counts, time = rappor.encode_string_light(in_list)\n",
    "                start_time = timeit.default_timer()\n",
    "                prob_est_3 = rappor.decode_counts(counts,n) # estimate the original underlying distribution\n",
    "                t3 = t3 + time + timeit.default_timer() - start_time\n",
    "            if encode_mode == 2:\n",
    "                out_list = rappor.encode_string_compress(in_list)\n",
    "                start_time = timeit.default_timer()\n",
    "                counts,temp = np.histogram(out_list,range(k+1))\n",
    "                prob_est_3 = rappor.decode_counts(counts,n) # estimate the original underlying distribution\n",
    "                t3 = t3 + timeit.default_timer() - start_time\n",
    "            count3 = count3 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_3)], ord=1) \n",
    "            count2_3 = count2_3 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_3)], ord=2)**2\n",
    "\n",
    "            #k-HR\n",
    "            outp_4 = hr.encode_string(in_list) \n",
    "            start_time = timeit.default_timer()\n",
    "            prob_est_4 = hr.decode_string(outp_4) # estimate the original underlying distribution\n",
    "            t4 = t4 + timeit.default_timer() - start_time\n",
    "            count4 = count4 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_4)], ord=1) \n",
    "            count2_4 = count2_4 + np.linalg.norm([a_i - b_i for a_i, b_i in zip(prob, prob_est_4)], ord=2)**2\n",
    "\n",
    "        l1_1[r-1] = count1/float(rep)\n",
    "        l1_2[r-1] = count2/float(rep)\n",
    "        l1_3[r-1] = count3/float(rep)\n",
    "        l1_4[r-1] = count4/float(rep)\n",
    "        \n",
    "        l2_1[r-1] = count2_1/float(rep)\n",
    "        l2_2[r-1] = count2_2/float(rep)\n",
    "        l2_3[r-1] = count2_3/float(rep)\n",
    "        l2_4[r-1] = count2_4/float(rep)\n",
    "        \n",
    "        t1_1[r-1] = t1/float(rep)\n",
    "        t1_2[r-1] = t2/float(rep)\n",
    "        t1_3[r-1] = t3/float(rep)\n",
    "        t1_4[r-1] = t4/float(rep)\n",
    "        \n",
    "    plt.figure()\n",
    "    plt.plot(indicies,l1_1, label = 'subset')\n",
    "    plt.plot(indicies,l1_2, label = 'rr')\n",
    "    plt.plot(indicies,l1_3, label = 'rappor')\n",
    "    plt.plot(indicies,l1_4, label = 'hr')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(indicies,l2_1, label = 'subset')\n",
    "    plt.plot(indicies,l2_2, label = 'rr')\n",
    "    plt.plot(indicies,l2_3, label = 'rappor')\n",
    "    plt.plot(indicies,l2_4, label = 'hr')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.plot(indicies,t1_1, label = 'subset')\n",
    "    plt.plot(indicies,t1_2, label = 'rr')\n",
    "    plt.plot(indicies,t1_3, label = 'rappor')\n",
    "    plt.plot(indicies,t1_4, label = 'hr')\n",
    "    plt.legend()\n",
    "    time = datetime.datetime.now().strftime(\"%m_%d_%H_%M\")\n",
    "\n",
    "    #save all the data into a mat file with time stamp\n",
    "    data = {\n",
    "        'time' : time,\n",
    "        'absz' : k,\n",
    "        'privacy' : eps,\n",
    "        'repetition' : rep,\n",
    "        'indices' : indicies, # indices of each point (number of samples)\n",
    "        'subset_error': l1_1, #l1 error for each point\n",
    "        'rr_error': l1_2,\n",
    "        'rappor_error': l1_3,\n",
    "        'hr_error': l1_4,\n",
    "        'subset_error_l2': l2_1, #l2 error for each point\n",
    "        'rr_error_l2': l2_2,\n",
    "        'rappor_error_l2': l2_3,\n",
    "        'hr_error_l2': l2_4,\n",
    "        'subset_time': t1_1, #decoding time for each point\n",
    "        'rr_time': t1_2,\n",
    "        'rappor_time': t1_3,\n",
    "        'hr_time': t1_4,\n",
    "        'prob': prob,\n",
    "        'dist': dist\n",
    "    }\n",
    "    para = 'k_{}_eps_{}_'.format(k,eps)\n",
    "    filename = 'Data/data_' + dist + '_' + para + time\n",
    "    io.savemat(filename,data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Testing script for comparison\n",
    "k = 100 #absz\n",
    "eps = 2 # privacy_para\n",
    "rep = 1 #repetition time for each point\n",
    "points = 10 # total number of points\n",
    "step_sz = 50000 # step size between two points\n",
    "init = 1 #initial step\n",
    "\n",
    "for dist in ['Geometric']:\n",
    "    print(dist)\n",
    "    for eps in [2]:\n",
    "        print(datetime.datetime.now())\n",
    "        data = test(k,eps,rep,points,step_sz,init,dist,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
